from lxml import html, etree
import requests
from bs4 import BeautifulSoup
import os

from urllib.parse import urlparse

urlbase = "https://dr.library.brocku.ca"


#INSERT THE URL OF THE FULL ITEM RECORD OF AN OBJECT HERE
webpageLink = "http://dr.library.brocku.ca/handle/10464/6070?show=full"




page = requests.get(webpageLink)
soup = BeautifulSoup(page.content, 'html.parser')







#This part makes a folder with the name of the 
narrowed_title = "blank"

for x in soup.find('title'):
    narrowed_title = x.extract()


#os.mkdir(narrowed_title)






#This part grabs the files from the page and downloads them to the folder
narrowed_file = soup.find_all('div', class_='file-link' )
link = []

for narrowed_file in narrowed_file:
    link.append(narrowed_file.find('a')['href'])

file_num = 0

for link in link:
    file_num = file_num + 1
    url = (urlbase + link)
    
    paresed_url = urlparse(link)
    parsed_name_of_file = os.path.basename(paresed_url.path)
    
    r = requests.get(url, allow_redirects=True)
    open(parsed_name_of_file, 'wb').write(r.content)



















#bodyonly = soup.find('body')
#print(bodyonly)
#page = requests.get("https://dr.library.brocku.ca/handle/10464/6071")
#print(page.content)
#extractedHtml = html.fromstring(page.content)
#print(extractedHtml)
#Title = extractedHtml.xpath("/html/body/center/h1")
#print(bookTitle[0].text)
